{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Dictionary\n",
    "\n",
    "| Variable | Definition | Key |\n",
    "| --- | --- | --- |\n",
    "| survived | Survival | 0 = No, 1 = Yes |\n",
    "| pclass|\tTicket class\t|1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "| sex|\tSex\t|\n",
    "| Age|\tAge in years\t|\n",
    "| sibsp|\t# of siblings / spouses aboard the Titanic\t|\n",
    "| parch|\t# of parents / children aboard the Titanic\t|\n",
    "| ticket|\tTicket number\t|\n",
    "| fare|\tPassenger fare\t|\n",
    "| cabin|\tCabin number\t|\n",
    "| embarked|\tPort of Embarkation\t|C = Cherbourg, Q = Queenstown, S = Southampton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"titanic/train.csv\")\n",
    "train_data.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      0\n",
       "Survived         0\n",
       "Pclass           0\n",
       "Name             0\n",
       "Sex              0\n",
       "Age            177\n",
       "SibSp            0\n",
       "Parch            0\n",
       "Ticket           0\n",
       "Fare             0\n",
       "Cabin          687\n",
       "Embarked         2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = train_data[\"Age\"].hist(bins=15, density=True, stacked=True, color='teal', alpha=0.6)\n",
    "train_data[\"Age\"].plot(kind='density', color='teal')\n",
    "ax.set(xlabel='Age')\n",
    "plt.xlim(-10,85)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena grafik \"Age\" lebih condong ke kiri, menggunakan rata-rata usia dapat memberi kita hasil yang bias. Oleh karena itu, saya memutuskan untuk menggunakan median untuk mengisi nilai yang hilang."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Age\"].fillna(train_data[\"Age\"].median(skipna=True), inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked Feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):\n",
      "S    644\n",
      "C    168\n",
      "Q     77\n",
      "Name: Embarked, dtype: int64\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Boarded passengers grouped by port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton):')\n",
    "print(train_data['Embarked'].value_counts())\n",
    "sns.countplot(x='Embarked', data=train_data, palette='Set2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karena pelabuhan keberangkatan yang paling umum adalah S (Southampton), maya saya akan mengisi 2 data hilang dengan \"S\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data[\"Embarked\"].fillna(train_data['Embarked'].value_counts().idxmax(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin Feature\n",
    "\n",
    "Karena data yang hilang pada kolom cabin terlalu banyak, maka saya memutuskan untuk menghapus kolom tersebut. Lagipula fitur tersebut juga tidak akan berguna untuk eksplorasi saya."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.drop('Cabin', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Train Setelah di Proses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    0\n",
       "Survived       0\n",
       "Pclass         0\n",
       "Name           0\n",
       "Sex            0\n",
       "Age            0\n",
       "SibSp          0\n",
       "Parch          0\n",
       "Ticket         0\n",
       "Fare           0\n",
       "Embarked       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  \\\n",
       "0           0       3  22.0      1      0   7.2500           0         1   \n",
       "1           1       1  38.0      1      0  71.2833           1         0   \n",
       "2           1       3  26.0      0      0   7.9250           1         0   \n",
       "3           1       1  35.0      1      0  53.1000           1         0   \n",
       "4           0       3  35.0      0      0   8.0500           0         1   \n",
       "..        ...     ...   ...    ...    ...      ...         ...       ...   \n",
       "886         0       2  27.0      0      0  13.0000           0         1   \n",
       "887         1       1  19.0      0      0  30.0000           1         0   \n",
       "888         0       3  28.0      1      2  23.4500           1         0   \n",
       "889         1       1  26.0      0      0  30.0000           0         1   \n",
       "890         0       3  32.0      0      0   7.7500           0         1   \n",
       "\n",
       "     Embarked_C  Embarked_Q  Embarked_S  \n",
       "0             0           0           1  \n",
       "1             1           0           0  \n",
       "2             0           0           1  \n",
       "3             0           0           1  \n",
       "4             0           0           1  \n",
       "..          ...         ...         ...  \n",
       "886           0           0           1  \n",
       "887           0           0           1  \n",
       "888           0           0           1  \n",
       "889           1           0           0  \n",
       "890           0           1           0  \n",
       "\n",
       "[891 rows x 11 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = train_data.drop(['PassengerId', 'Ticket', 'Name'], axis=1)\n",
    "train_data = pd.get_dummies(train_data)\n",
    "train_data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass   Age  SibSp  Parch     Fare  Sex_female  Sex_male  Embarked_C  \\\n",
       "0       3  22.0      1      0   7.2500           0         1           0   \n",
       "1       1  38.0      1      0  71.2833           1         0           1   \n",
       "2       3  26.0      0      0   7.9250           1         0           0   \n",
       "3       1  35.0      1      0  53.1000           1         0           0   \n",
       "4       3  35.0      0      0   8.0500           0         1           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Survived  \n",
       "0           0           1         0  \n",
       "1           0           0         1  \n",
       "2           0           1         1  \n",
       "3           0           1         1  \n",
       "4           0           1         0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = train_data.drop(\"Survived\", axis=1)\n",
    "y = train_data[\"Survived\"]\n",
    "pd.concat([X, y], axis=1).head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building 5-folds validation\n",
    "\n",
    "Pembagian data latih dan data uji ke dalam bentuk 5-folds validation digunakan untuk menguji kinerja model secara lebih akurat dan menghindari bias yang mungkin muncul dalam evaluasi model dengan satu set data uji dan latih. Dengan membagi data menjadi lima bagian, model dievaluasi secara iteratif dengan menggunakan kombinasi berbeda antara data uji dan latih, sehingga memberikan estimasi kinerja yang lebih stabil dan mengurangi risiko overfitting, serta memaksimalkan penggunaan data yang terbatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0:\n",
      "\tTrain: index length = 712\n",
      "\tTest:  index length= 179\n",
      "Fold 1:\n",
      "\tTrain: index length = 713\n",
      "\tTest:  index length= 178\n",
      "Fold 2:\n",
      "\tTrain: index length = 713\n",
      "\tTest:  index length= 178\n",
      "Fold 3:\n",
      "\tTrain: index length = 713\n",
      "\tTest:  index length= 178\n",
      "Fold 4:\n",
      "\tTrain: index length = 713\n",
      "\tTest:  index length= 178\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "\n",
    "for i, (train_index, test_index) in enumerate(skf.split(X, y)):\n",
    "    print(f\"Fold {i}:\")\n",
    "    print(f\"\\tTrain: index length = {len(train_index)}\")\n",
    "    print(f\"\\tTest:  index length= {len(test_index)}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Models\n",
    "\n",
    "Definisikan semua model yang akan digunakan dalam memprediksi keselamatan penumpang kapal Titanic. Model-model yang digunakan meliputi Logistic Regression, Naive Bayes, K-Nearest Neighbors, Linear SVM, RBF SVM, MLP dengan 1 hidden layer, MLP dengan 2 hidden layers, Decision Tree, Random Forest, dan Gradient Boosting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [\n",
    "    ('Logistic Regression', LogisticRegression(random_state=42)),\n",
    "    ('Naive Bayes', GaussianNB()),\n",
    "    ('K-Nearest Neighbors', KNeighborsClassifier()),\n",
    "    ('Linear SVM', LinearSVC(random_state=42)),\n",
    "    ('RBF Kernel SVM', SVC(kernel='rbf', random_state=42)),\n",
    "    ('MLP (1 hidden layer)', MLPClassifier(\n",
    "        hidden_layer_sizes=(100,), random_state=42)),\n",
    "    ('MLP (2 hidden layers)', MLPClassifier(\n",
    "        hidden_layer_sizes=(100, 100), random_state=42)),\n",
    "    ('Decision Tree', DecisionTreeClassifier(random_state=42)),\n",
    "    ('Random Forest', RandomForestClassifier(random_state=42)),\n",
    "    ('Gradient Boosting', GradientBoostingClassifier(random_state=42))\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Logistic Regression\n",
      "Evaluating Naive Bayes\n",
      "Evaluating K-Nearest Neighbors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Linear SVM\n",
      "Evaluating RBF SVM\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\svm\\_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP (1 hidden layer)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "c:\\Python311\\Lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:686: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating MLP (2 hidden layers)\n",
      "Evaluating Decision Tree\n",
      "Evaluating Random Forest\n",
      "Evaluating Gradient Boosting\n",
      "\n",
      "All models trained successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# mendefinisikan daftar metrik performa\n",
    "performance_metrics = ['accuracy', 'precision_macro', 'recall_macro', 'f1_macro']\n",
    "\n",
    "# DataFrame kosong untuk menyimpan skor kinerja dari setiap model dan fold\n",
    "performance = pd.DataFrame(\n",
    "    columns=['Model', 'Fold', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "average_score = pd.DataFrame(\n",
    "    columns=['Model', 'Accuracy', 'Precision', 'Recall', 'F1'])\n",
    "\n",
    "# loop untuk setiap model dan melaksanakan cross-validation\n",
    "for name, model in models:\n",
    "    print(f\"Evaluating {name}\")\n",
    "    cv_results = cross_validate(model, X, y, cv=skf, scoring=performance_metrics)\n",
    "\n",
    "    # mengisi nilai performa ke DataFrame 'performance'\n",
    "    for i in range(skf.n_splits):\n",
    "        performance.loc[len(performance)] = [name, i+1, cv_results['test_accuracy'][i],\n",
    "                                   cv_results['test_precision_macro'][i],\n",
    "                                   cv_results['test_recall_macro'][i],\n",
    "                                   cv_results['test_f1_macro'][i]]\n",
    "\n",
    "    # mengisi rata-rata nilai performa ke DataFrame 'average_score'\n",
    "    average_score.loc[len(average_score)] = [name, cv_results['test_accuracy'].mean(),\n",
    "                                cv_results['test_precision_macro'].mean(),\n",
    "                                cv_results['test_recall_macro'].mean(),\n",
    "                                cv_results['test_f1_macro'].mean()]\n",
    "else:\n",
    "    print('\\nAll models trained successfully.\\n')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performa setiap model dalam bentuk 5-folds validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Fold</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>1</td>\n",
       "      <td>0.782123</td>\n",
       "      <td>0.770204</td>\n",
       "      <td>0.768709</td>\n",
       "      <td>0.769429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>2</td>\n",
       "      <td>0.797753</td>\n",
       "      <td>0.788515</td>\n",
       "      <td>0.777406</td>\n",
       "      <td>0.781892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>3</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.789283</td>\n",
       "      <td>0.761631</td>\n",
       "      <td>0.770194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>4</td>\n",
       "      <td>0.780899</td>\n",
       "      <td>0.767917</td>\n",
       "      <td>0.769385</td>\n",
       "      <td>0.768623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.824779</td>\n",
       "      <td>0.817179</td>\n",
       "      <td>0.820492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>1</td>\n",
       "      <td>0.765363</td>\n",
       "      <td>0.754329</td>\n",
       "      <td>0.763175</td>\n",
       "      <td>0.757108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>2</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.762311</td>\n",
       "      <td>0.759225</td>\n",
       "      <td>0.760656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>3</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.781712</td>\n",
       "      <td>0.772861</td>\n",
       "      <td>0.776556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>4</td>\n",
       "      <td>0.786517</td>\n",
       "      <td>0.775082</td>\n",
       "      <td>0.768316</td>\n",
       "      <td>0.771239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>5</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.804245</td>\n",
       "      <td>0.808736</td>\n",
       "      <td>0.806235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>1</td>\n",
       "      <td>0.743017</td>\n",
       "      <td>0.729201</td>\n",
       "      <td>0.720685</td>\n",
       "      <td>0.723988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>2</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.732217</td>\n",
       "      <td>0.730882</td>\n",
       "      <td>0.731523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>3</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.664407</td>\n",
       "      <td>0.655615</td>\n",
       "      <td>0.658443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>4</td>\n",
       "      <td>0.702247</td>\n",
       "      <td>0.683558</td>\n",
       "      <td>0.669251</td>\n",
       "      <td>0.673281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>5</td>\n",
       "      <td>0.707865</td>\n",
       "      <td>0.691373</td>\n",
       "      <td>0.684350</td>\n",
       "      <td>0.686959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.776536</td>\n",
       "      <td>0.778876</td>\n",
       "      <td>0.739855</td>\n",
       "      <td>0.749300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.697143</td>\n",
       "      <td>0.610695</td>\n",
       "      <td>0.600641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.762884</td>\n",
       "      <td>0.756417</td>\n",
       "      <td>0.759199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.719101</td>\n",
       "      <td>0.751351</td>\n",
       "      <td>0.649198</td>\n",
       "      <td>0.647999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>5</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.725153</td>\n",
       "      <td>0.573195</td>\n",
       "      <td>0.532563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>1</td>\n",
       "      <td>0.698324</td>\n",
       "      <td>0.722644</td>\n",
       "      <td>0.627602</td>\n",
       "      <td>0.620644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>2</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.678404</td>\n",
       "      <td>0.621925</td>\n",
       "      <td>0.619658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>3</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.586898</td>\n",
       "      <td>0.572115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>4</td>\n",
       "      <td>0.685393</td>\n",
       "      <td>0.704200</td>\n",
       "      <td>0.607888</td>\n",
       "      <td>0.595257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>5</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.655914</td>\n",
       "      <td>0.594469</td>\n",
       "      <td>0.582812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.804469</td>\n",
       "      <td>0.793447</td>\n",
       "      <td>0.794993</td>\n",
       "      <td>0.794192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.792852</td>\n",
       "      <td>0.787567</td>\n",
       "      <td>0.789946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.799696</td>\n",
       "      <td>0.776337</td>\n",
       "      <td>0.784242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.804969</td>\n",
       "      <td>0.799465</td>\n",
       "      <td>0.801949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.826501</td>\n",
       "      <td>0.814519</td>\n",
       "      <td>0.819399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.806718</td>\n",
       "      <td>0.801383</td>\n",
       "      <td>0.803787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>2</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.779750</td>\n",
       "      <td>0.781283</td>\n",
       "      <td>0.780489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>3</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.810633</td>\n",
       "      <td>0.778075</td>\n",
       "      <td>0.788006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>4</td>\n",
       "      <td>0.792135</td>\n",
       "      <td>0.779750</td>\n",
       "      <td>0.781283</td>\n",
       "      <td>0.780489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.816270</td>\n",
       "      <td>0.817910</td>\n",
       "      <td>0.817061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>1</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.788313</td>\n",
       "      <td>0.785046</td>\n",
       "      <td>0.786566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>2</td>\n",
       "      <td>0.820225</td>\n",
       "      <td>0.809598</td>\n",
       "      <td>0.820856</td>\n",
       "      <td>0.813417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>3</td>\n",
       "      <td>0.747191</td>\n",
       "      <td>0.732416</td>\n",
       "      <td>0.733690</td>\n",
       "      <td>0.733027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>4</td>\n",
       "      <td>0.769663</td>\n",
       "      <td>0.756152</td>\n",
       "      <td>0.754679</td>\n",
       "      <td>0.755388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>5</td>\n",
       "      <td>0.803371</td>\n",
       "      <td>0.795093</td>\n",
       "      <td>0.786265</td>\n",
       "      <td>0.789946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>1</td>\n",
       "      <td>0.837989</td>\n",
       "      <td>0.836835</td>\n",
       "      <td>0.816864</td>\n",
       "      <td>0.824278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>2</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.803146</td>\n",
       "      <td>0.807888</td>\n",
       "      <td>0.805258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>3</td>\n",
       "      <td>0.775281</td>\n",
       "      <td>0.763765</td>\n",
       "      <td>0.753610</td>\n",
       "      <td>0.757658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>4</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.804020</td>\n",
       "      <td>0.802273</td>\n",
       "      <td>0.803117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>5</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.828639</td>\n",
       "      <td>0.811860</td>\n",
       "      <td>0.818244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>1</td>\n",
       "      <td>0.826816</td>\n",
       "      <td>0.827016</td>\n",
       "      <td>0.802372</td>\n",
       "      <td>0.810853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>2</td>\n",
       "      <td>0.859551</td>\n",
       "      <td>0.857853</td>\n",
       "      <td>0.841444</td>\n",
       "      <td>0.848035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>3</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.823143</td>\n",
       "      <td>0.779813</td>\n",
       "      <td>0.791724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>4</td>\n",
       "      <td>0.808989</td>\n",
       "      <td>0.800890</td>\n",
       "      <td>0.789305</td>\n",
       "      <td>0.794010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>5</td>\n",
       "      <td>0.825843</td>\n",
       "      <td>0.826293</td>\n",
       "      <td>0.801955</td>\n",
       "      <td>0.810267</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Fold  Accuracy  Precision    Recall        F1\n",
       "0     Logistic Regression     1  0.782123   0.770204  0.768709  0.769429\n",
       "1     Logistic Regression     2  0.797753   0.788515  0.777406  0.781892\n",
       "2     Logistic Regression     3  0.792135   0.789283  0.761631  0.770194\n",
       "3     Logistic Regression     4  0.780899   0.767917  0.769385  0.768623\n",
       "4     Logistic Regression     5  0.831461   0.824779  0.817179  0.820492\n",
       "5             Naive Bayes     1  0.765363   0.754329  0.763175  0.757108\n",
       "6             Naive Bayes     2  0.775281   0.762311  0.759225  0.760656\n",
       "7             Naive Bayes     3  0.792135   0.781712  0.772861  0.776556\n",
       "8             Naive Bayes     4  0.786517   0.775082  0.768316  0.771239\n",
       "9             Naive Bayes     5  0.814607   0.804245  0.808736  0.806235\n",
       "10    K-Nearest Neighbors     1  0.743017   0.729201  0.720685  0.723988\n",
       "11    K-Nearest Neighbors     2  0.747191   0.732217  0.730882  0.731523\n",
       "12    K-Nearest Neighbors     3  0.685393   0.664407  0.655615  0.658443\n",
       "13    K-Nearest Neighbors     4  0.702247   0.683558  0.669251  0.673281\n",
       "14    K-Nearest Neighbors     5  0.707865   0.691373  0.684350  0.686959\n",
       "15             Linear SVM     1  0.776536   0.778876  0.739855  0.749300\n",
       "16             Linear SVM     2  0.685393   0.697143  0.610695  0.600641\n",
       "17             Linear SVM     3  0.775281   0.762884  0.756417  0.759199\n",
       "18             Linear SVM     4  0.719101   0.751351  0.649198  0.647999\n",
       "19             Linear SVM     5  0.662921   0.725153  0.573195  0.532563\n",
       "20                RBF SVM     1  0.698324   0.722644  0.627602  0.620644\n",
       "21                RBF SVM     2  0.685393   0.678404  0.621925  0.619658\n",
       "22                RBF SVM     3  0.662921   0.654762  0.586898  0.572115\n",
       "23                RBF SVM     4  0.685393   0.704200  0.607888  0.595257\n",
       "24                RBF SVM     5  0.662921   0.655914  0.594469  0.582812\n",
       "25   MLP (1 hidden layer)     1  0.804469   0.793447  0.794993  0.794192\n",
       "26   MLP (1 hidden layer)     2  0.803371   0.792852  0.787567  0.789946\n",
       "27   MLP (1 hidden layer)     3  0.803371   0.799696  0.776337  0.784242\n",
       "28   MLP (1 hidden layer)     4  0.814607   0.804969  0.799465  0.801949\n",
       "29   MLP (1 hidden layer)     5  0.831461   0.826501  0.814519  0.819399\n",
       "30  MLP (2 hidden layers)     1  0.815642   0.806718  0.801383  0.803787\n",
       "31  MLP (2 hidden layers)     2  0.792135   0.779750  0.781283  0.780489\n",
       "32  MLP (2 hidden layers)     3  0.808989   0.810633  0.778075  0.788006\n",
       "33  MLP (2 hidden layers)     4  0.792135   0.779750  0.781283  0.780489\n",
       "34  MLP (2 hidden layers)     5  0.825843   0.816270  0.817910  0.817061\n",
       "35          Decision Tree     1  0.798883   0.788313  0.785046  0.786566\n",
       "36          Decision Tree     2  0.820225   0.809598  0.820856  0.813417\n",
       "37          Decision Tree     3  0.747191   0.732416  0.733690  0.733027\n",
       "38          Decision Tree     4  0.769663   0.756152  0.754679  0.755388\n",
       "39          Decision Tree     5  0.803371   0.795093  0.786265  0.789946\n",
       "40          Random Forest     1  0.837989   0.836835  0.816864  0.824278\n",
       "41          Random Forest     2  0.814607   0.803146  0.807888  0.805258\n",
       "42          Random Forest     3  0.775281   0.763765  0.753610  0.757658\n",
       "43          Random Forest     4  0.814607   0.804020  0.802273  0.803117\n",
       "44          Random Forest     5  0.831461   0.828639  0.811860  0.818244\n",
       "45      Gradient Boosting     1  0.826816   0.827016  0.802372  0.810853\n",
       "46      Gradient Boosting     2  0.859551   0.857853  0.841444  0.848035\n",
       "47      Gradient Boosting     3  0.814607   0.823143  0.779813  0.791724\n",
       "48      Gradient Boosting     4  0.808989   0.800890  0.789305  0.794010\n",
       "49      Gradient Boosting     5  0.825843   0.826293  0.801955  0.810267"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(performance)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performa rata-rata tiap model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.796874</td>\n",
       "      <td>0.788139</td>\n",
       "      <td>0.778862</td>\n",
       "      <td>0.782126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.786780</td>\n",
       "      <td>0.775536</td>\n",
       "      <td>0.774462</td>\n",
       "      <td>0.774359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.717143</td>\n",
       "      <td>0.700151</td>\n",
       "      <td>0.692157</td>\n",
       "      <td>0.694839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.723847</td>\n",
       "      <td>0.743081</td>\n",
       "      <td>0.665872</td>\n",
       "      <td>0.657940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RBF SVM</td>\n",
       "      <td>0.678991</td>\n",
       "      <td>0.683185</td>\n",
       "      <td>0.607756</td>\n",
       "      <td>0.598097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MLP (1 hidden layer)</td>\n",
       "      <td>0.811456</td>\n",
       "      <td>0.803493</td>\n",
       "      <td>0.794576</td>\n",
       "      <td>0.797946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>MLP (2 hidden layers)</td>\n",
       "      <td>0.806949</td>\n",
       "      <td>0.798624</td>\n",
       "      <td>0.791987</td>\n",
       "      <td>0.793966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.787866</td>\n",
       "      <td>0.776314</td>\n",
       "      <td>0.776107</td>\n",
       "      <td>0.775669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.814789</td>\n",
       "      <td>0.807281</td>\n",
       "      <td>0.798499</td>\n",
       "      <td>0.801711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Gradient Boosting</td>\n",
       "      <td>0.827161</td>\n",
       "      <td>0.827039</td>\n",
       "      <td>0.802978</td>\n",
       "      <td>0.810978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Model  Accuracy  Precision    Recall        F1\n",
       "0    Logistic Regression  0.796874   0.788139  0.778862  0.782126\n",
       "1            Naive Bayes  0.786780   0.775536  0.774462  0.774359\n",
       "2    K-Nearest Neighbors  0.717143   0.700151  0.692157  0.694839\n",
       "3             Linear SVM  0.723847   0.743081  0.665872  0.657940\n",
       "4                RBF SVM  0.678991   0.683185  0.607756  0.598097\n",
       "5   MLP (1 hidden layer)  0.811456   0.803493  0.794576  0.797946\n",
       "6  MLP (2 hidden layers)  0.806949   0.798624  0.791987  0.793966\n",
       "7          Decision Tree  0.787866   0.776314  0.776107  0.775669\n",
       "8          Random Forest  0.814789   0.807281  0.798499  0.801711\n",
       "9      Gradient Boosting  0.827161   0.827039  0.802978  0.810978"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(average_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "highest accuracy score: Gradient Boosting\n",
      "highest precision score: Gradient Boosting\n",
      "highest recall score: Gradient Boosting\n",
      "highest F1 score: Gradient Boosting\n",
      "\n",
      "lowest accuracy score: RBF SVM\n",
      "lowest precision score: RBF SVM\n",
      "lowest recall score: RBF SVM\n",
      "lowest F1 score: RBF SVM\n"
     ]
    }
   ],
   "source": [
    "# Find max values\n",
    "best_accuracy_model = average_score.loc[average_score['Accuracy'].idxmax(), 'Model']\n",
    "best_precision_model = average_score.loc[average_score['Precision'].idxmax(), 'Model']\n",
    "best_recall_model = average_score.loc[average_score['Recall'].idxmax(), 'Model']\n",
    "best_f1_model = average_score.loc[average_score['F1'].idxmax(), 'Model']\n",
    "\n",
    "print('highest accuracy score:', best_accuracy_model)\n",
    "print('highest precision score:', best_precision_model)\n",
    "print('highest recall score:', best_recall_model)\n",
    "print('highest F1 score:', best_f1_model)\n",
    "print()\n",
    "\n",
    "# Find lowest values\n",
    "worst_accuracy_model = average_score.loc[average_score['Accuracy'].idxmin(), 'Model']\n",
    "worst_precision_model = average_score.loc[average_score['Precision'].idxmin(), 'Model']\n",
    "worst_recall_model = average_score.loc[average_score['Recall'].idxmin(), 'Model']\n",
    "worst_f1_model = average_score.loc[average_score['F1'].idxmin(), 'Model']\n",
    "\n",
    "print('lowest accuracy score:', worst_accuracy_model)\n",
    "print('lowest precision score:', worst_precision_model)\n",
    "print('lowest recall score:', worst_recall_model)\n",
    "print('lowest F1 score:', worst_f1_model)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "Model Gradient Boosting adalah model terbaik untuk memprediksi keselamatan penumpang kapal Titanic. Hal tersebut dapat dilihat dari nilai rata-rata performa metric yang memiliki nilai tertinggi dibanding model lainnya. Sedangkan, model RBF Kernel SVM merupakan model terburuk untuk memprediksi keselamatan penumpang kapal Titanic karena memperoleh nilai rata-rata performa metric yang paling rendah. \n",
    "\n",
    "Dalam kasus dataset Titanic, Gradient Boosting memiliki tingkat performa terbaik karena model ini memiliki kemampuan yang baik dalam menangani masalah klasifikasi dengan dataset yang kompleks dan beragam fitur. Gradient Boosting mampu membangun sekumpulan pohon keputusan yang kuat dan memperbaikinya secara bertahap dengan menggabungkan hasil prediksi dari pohon sebelumnya, sehingga mampu mengatasi masalah overfitting dan memberikan prediksi yang akurat.\n",
    "\n",
    "Di sisi lain, SVM dengan kernel RBF (Radial Basis Function) menghasilkan tingkat performa yang lebih rendah dalam kasus dataset Titanic. Hal ini bisa terjadi karena SVM dengan kernel RBF memiliki kecenderungan untuk overfitting ketika dihadapkan pada dataset yang memiliki fitur yang banyak atau dimensi yang tinggi seperti dataset Titanic. Selain itu, dalam SVM dengan kernel RBF, ada parameter kernel yang harus disesuaikan dengan baik untuk mendapatkan performa yang optimal. Jika parameter kernel tidak disesuaikan dengan baik, performa model dapat menurun.\n",
    "\n",
    "Namun, penting untuk dicatat bahwa performa model-machine learning dapat bervariasi tergantung pada berbagai faktor, termasuk praproses data yang dilakukan, pengaturan parameter model, dan metrik evaluasi yang digunakan. Oleh karena itu, eksperimen yang lebih lengkap dan pengaturan yang lebih tepat diperlukan untuk memastikan hasil evaluasi performa model yang lebih akurat dan dapat diandalkan."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
